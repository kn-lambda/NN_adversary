# NN_adversary

Experiments of adversarial attack and defense for Neural Net.

## Frame Work
chainer

## Data
mnist  
cifar10  
fashion-mnist 

## Attack
(Iterative) Fast Gradient Sign  
Carlini and Wagner's L2  
Black Box version of Carlini and Wagner's L2

## References
"Towards Evaluating the Robustness of Neural Networks"  
by Nicholas Carlini and David Wagner  
at IEEE Symposium on Security & Privacy, 2017

"ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models"  
by Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, Cho-Jui Hsieh  
at 10th ACM Workshop on Artificial Intelligence and Security, 2017
